{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Depth 2, Train acc: 0.6294, Test acc: 0.6306, Val acc: 0.6308\n",
      "[19:35:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Depth 3, Train acc: 0.6353, Test acc: 0.6358, Val acc: 0.6353\n",
      "[19:35:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Depth 4, Train acc: 0.64, Test acc: 0.638, Val acc: 0.6385\n",
      "[19:36:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Depth 5, Train acc: 0.6434, Test acc: 0.6413, Val acc: 0.6414\n",
      "[19:37:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Depth 6, Train acc: 0.6481, Test acc: 0.6426, Val acc: 0.6428\n"
     ]
    }
   ],
   "source": [
    "def grid_search(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        min_iter: int = 3,\n",
    "        max_iter: int = 20\n",
    ") -> None:\n",
    "    for i in range(min_iter, max_iter):\n",
    "\n",
    "        __MODEL_TYPE = \"XGBClassifier\"\n",
    "        __MIN_SAMPLES_LEAF = 100\n",
    "        __RANDOM_STATE = 42\n",
    "\n",
    "        if _MODEL_TYPE == \"DecisionTreeClassifier\":\n",
    "            dt = DecisionTreeClassifier(\n",
    "                max_depth=i,\n",
    "                min_samples_leaf=_MIN_SAMPLES_LEAF,\n",
    "                random_state=_RANDOM_STATE\n",
    "            )\n",
    "        else:\n",
    "            dt = xgb.XGBClassifier(\n",
    "                max_depth=i,\n",
    "                min_child_weight=_MIN_CHILD_WEIGHT,\n",
    "                n_estimators=_N_ESTIMATORS,\n",
    "                random_state=_RANDOM_STATE,\n",
    "                use_label_encoder=False\n",
    "            )\n",
    "\n",
    "        dt.fit(X_train, y_train)\n",
    "        accuracy_train = dt.score(X_train, y_train)\n",
    "        accuracy_test = dt.score(X_test, y_test)\n",
    "        accuracy_val = dt.score(X_val, y_val)\n",
    "        print(f\"Depth {i}, Train acc: {np.round(accuracy_train, 4)}, Test acc: {np.round(accuracy_test, 4)}, Val acc: {np.round(accuracy_val, 4)}\")\n",
    "\n",
    "        model_evaluator = ModelEvaluator(dt, TARGET, X_test, y_test)\n",
    "        model_evaluator.evaluate()\n",
    "        evaluation_result = model_evaluator.evaluation_result\n",
    "\n",
    "        reporter.append_new_evaluation(\n",
    "            model_type=__MODEL_TYPE,\n",
    "            max_depth=i,\n",
    "            min_samples_leaf=__MIN_SAMPLES_LEAF,\n",
    "            n_estimators=_N_ESTIMATORS,\n",
    "            min_child_weight=_MIN_CHILD_WEIGHT,\n",
    "            random_state=__RANDOM_STATE,\n",
    "            accuracy_train=model_evaluator.calculate_accuraty(X_train, y_train),\n",
    "            accuracy_test=model_evaluator.calculate_accuraty(X_test, y_test),\n",
    "            accuracy_val=model_evaluator.calculate_accuraty(X_val, y_val),\n",
    "            success_sum=evaluation_result['Success'].sum(),\n",
    "            success_count=evaluation_result['Success'].count(),\n",
    "            target_mean=evaluation_result[TARGET].mean(),\n",
    "            auc_roc=model_evaluator.get_auc_roc(),\n",
    "            f1_score=model_evaluator.get_f1_score(),\n",
    "            recall=model_evaluator.confusion_matrix.get_recall(),\n",
    "            precision=model_evaluator.confusion_matrix.get_precision()\n",
    "        )\n",
    "\n",
    "# grid_search(X_train, y_train, X_test, y_test, val_df_X, val_df_y, 2, 7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}